<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="AuditoryBench++">
  <meta property="og:title" content="AuditoryBench++"/>
  <meta property="og:description" content="AuditoryBench++ Project Page"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>AuditoryBench++</title>
<!--   <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet"> -->

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

</head>

<style>
  .item {
    padding-bottom: 20px; 
    max-width: 100%;
}
  
  .case-study-container {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 20px;
    width: 100%;
}

  
.case-study-box {
    width: 65%; 
    max-width: 1000px;
    border-radius: 15px;
    border: 1px solid #ccc;
    padding: 20px;
    box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.1);
    text-align: left;
    background: white;
    display: flex;
    flex-direction: column;
    justify-content: space-between;
}

.model-row {
  display: flex;
  align-items: center;
  justify-content: space-between;
  width: 100%;
}

/* Mobile layout - flex direction changes */
@media (max-width: 768px) {
  .model-row {
    flex-direction: column;
  }
}

  .icon {
    font-size: 18px;
    margin-left: 5px;
  }


  .model-name {
    font-weight: bold;
  }

  .text-danger {
    color: red;
  }

  .text-success {
    color: green;
  }
  

  .audio-container {
    display: flex;
    align-items: center;
    margin-left: auto;
  }

  .audio-icon {
    font-size: 22px;
    margin-left: 10px;
    color: #007bff;
  }

  .case-study-container2 {
  display: flex;
  flex-direction: column;
  align-items: center;
  width: 100%;
  text-align: center; 
  margin-bottom: 40px;
}


  .case-study-box2 {
    width: 65%;
    max-width: 1000px;
    border-radius: 15px;
    border: 1px solid #ccc;
    padding: 15px; 
    box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.1);
    text-align: left;
    background: white;
    display: flex;
    flex-direction: column;
    justify-content: space-between;
  }

  .case-study-box2 p {
    font-size: 16px; 
  }

  .spectrogram-container {
    display: flex;
    justify-content: center;
    gap: 20px;
    flex-wrap: wrap;
    margin-top: 20px;
  }

  .spectrogram-box {
    display: flex;
    flex-direction: column;
    align-items: center;
    text-align: center;
    width: 250px; 
  }

  .spectrogram-box img {
    width: 250px; 
    height: auto;
    border: 1px solid #ddd;
    border-radius: 5px;
  }


  .spectrogram-label {
    font-size: 16px; 
    font-weight: bold;
    margin-bottom: 8px;
  }

  .audio-container2 {
    width: 100%; 
    display: flex;
    justify-content: center;
    background: rgba(255, 255, 255, 0.95);
    padding: 6px;
    border-radius: 5px;
    margin-bottom: 8px;
  } 


  .dki-section {
  margin-top: 100px !important; 
}

  .fusion-section {
  margin-top: 100px !important; 
}

.fusion-image-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  text-align: center;
  margin-top: 30px;
}

.fusion-image {
  max-width: 100%; 
  width: 600px;
  height: auto;
  border: 1px solid #ddd;
  border-radius: 10px;
  box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.1);
  margin-bottom: 50px;
}

  .carousel {
  max-width: 100%; 
}
</style>
  
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-3 publication-title">AuditoryBench++: Can Language Models Understand
Auditory Knowledge without Hearing?</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block"> 
                <a href="https://hj-ok.github.io" target="_blank">Hyunjong Ok</a><sup>1,2*</sup>,</span>
                <span class="author-block">
                  <a href="https://suho-yoo.github.io/" target="_blank">Suho Yoo</a><sup>2,3*</sup>,</span>
                  <span class="author-block">
                  <span>Hyeonjun Kim</span><sup>1</sup>,</span>
                  <span class="author-block">
                  <a href="https://mm.kaist.ac.kr/joon/" target="_blank">Joon Son Chung</a><sup>3</sup>,</span>
                  <span class="author-block">
                    <a href="https://jaeho-lee.github.io" target="_blank">Jaeho Lee</a><sup>1</sup>
                  </span>
              </div>


                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>POSTECH <sup>2</sup>HJ AILAB <sup>3</sup>KAIST  <br>ICASSP 2026 Submission</span>  
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>


<!--                   <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2503.16853.pdf" target="_blank" 
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/HJ-OK/AuditoryBenchpp" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            <!-- 이미지 추가 -->
<div class="has-text-centered" style="margin-top: 2rem;">
  <figure class="image is-inline-block">
    <img src="static/images/fig1.png" alt="AuditoryBench++ fig1" style="max-width: 600px;">
  </figure>
</div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
  </section>



  
  

      
<!-- Paper abstract -->
  <section class="section hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="section-title has-text-centered">
        <h3 class="title is-3">Abstract</h3>
      </div>
      <div class="content has-text-justified">
        <p style="font-size:18px; margin-top: 30px;">
            Even without directly hearing sounds, humans can effort
          lessly reason about auditory properties, such as pitch, 
          loudness, or sound-source associations, drawing on auditory commonsense. 
          In contrast, language models often lack this capability,
          limiting their effectiveness in multimodal interactions. 
          As the first step to address this gap, we present AuditoryBench++, 
          a comprehensive benchmark for evaluating auditory knowledge 
          and reasoning in text-only settings. The benchmark encompasses 
          tasks that range from basic auditory comparisons to contextually 
          grounded reasoning, enabling fine-grained analysis of how models process 
          and integrate auditory concepts. In addition, we introduce AIR-CoT, a 
          novel auditory imagination reasoning method that generates 
          and integrates auditory information during inference 
          through span detection with special tokens and knowledge 
          injection. Extensive experiments with recent LLMs and Multimodal LLMs 
          demonstrate that AIR-CoT consistently outperforms both 
          the off-the-shelf models and those augmented with prior techniques.
          </p>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Model Architecture Section -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop" style="margin-top: 10px;">
      <div class="section-title has-text-centered">
        <h3 class="title is-3">Details of the Pipeline</h3>
      </div>
      <div class="content has-text-left">
        <img src="static/images/dataset_pipeline.png" alt="Details of the Pipeline" style="display: inline-block;"/>
        <p style="font-size:18px; margin-top:30px;">
  The construction pipeline is presented below, with tasks grouped by their original resource.
</p>

<ul style="font-size:18px;">
  <li><b>AuditoryBench</b>
    <ul>
      <li><b>Pitch Comparison:</b> Derived from the <i>AuditoryBench</i> wiki set on sound pitch comparison. 
        This subset primarily consists of instrument-based pairs, allowing for objective and unambiguous 
        evaluations of relative pitch differences 
        (<a href="https://en.wikipedia.org/wiki/Range_(music)" target="_blank">Range (music)</a>).
      </li>
      <li><b>Animal Sound Recognition:</b> Constructed from the <i>AuditoryBench</i> wiki and test sets. 
        Three authors independently scored each sample on a 0–2 scale, and any item receiving a score of 0 
        from at least one annotator was removed. Inter-rater agreement was substantial 
        (Kendall’s W = 0.666; ICC(2,k) = 0.75; Cronbach’s α = 0.75), ensuring dataset consistency and reliability.
      </li>
    </ul>
  </li>

  <li><b>AudioTime</b>
    <ul>
      <li><b>Duration Comparison:</b> Built from segment-level annotations. Classes with fewer than 30 samples 
        were excluded, outliers were removed using the IQR rule, and only statistically significant contrasts 
        (p &lt; 0.01) were retained.
      </li>
      <li><b>Loudness Comparison:</b> Derived from the same source, with loudness measured by peak decibel 
        levels in each segment to ensure reliable intensity distinctions. 
      </li>
    </ul>
    <p style="margin-top: 0.2em; margin-bottom: 0;">Final filtering was applied by the authors 
to remove classes deemed unsuitable for either task.</p>
  </li>

  <li><b>MMAU</b>
    <ul>
      <li><b>Auditory Context Reasoning:</b> Adapted from the open MMAU set. Audio clips were first captioned 
        using Qwen2-Audio to capture salient auditory cues. The captions, together with the original questions, 
        were reformulated by GPT-4o into text-only problems while preserving reasoning objectives. 
        Human verification and refinement were applied to discard incoherent items and ensure naturalness 
        in a purely text-based setting.
      </li>
    </ul>
  </li>
</ul>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
  <section class="section hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="section-title has-text-centered">
        <h3 class="title is-3">Dataset Samples</h3>
      </div>
      <div class="content has-text-justified">
        <p style="font-size:18px; margin-top: 30px">
            TBD
          </p>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>TBD</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
